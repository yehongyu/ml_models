{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 1.15.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'collector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3544cc6e0754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tf version:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlagrange_lite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlagrange_lite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#from lagrange_lite.tensorflow import aop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/lagrange_lite/lagrange_lite/tensorflow/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlagrange_lite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJOB_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_insight_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/lagrange_lite/lagrange_lite/common/deep_insight_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/pyutil/pyutil/databus/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#/usr/bin/python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcollector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'collector'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tf version:', tf.__version__)\n",
    "from lagrange_lite.utils import io\n",
    "from lagrange_lite.tensorflow import train\n",
    "#from lagrange_lite.tensorflow import aop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aodandan/data/dnn/model/\n",
      "/Users/aodandan/data/dnn/train/{20191008}/part-*\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('train_paths', 'hdfs://haruna/recommend/data/group_comment/reckon_offline/tfrecord/{20191009}/part-*', 'HDFS paths to input files.')\n",
    "tf.app.flags.DEFINE_string(\"eval_paths\", 'hdfs://haruna/recommend/data/group_comment/reckon_offline/tfrecord/{20190902}/part-*', \"eval data path\")\n",
    "tf.app.flags.DEFINE_string('model_path', 'hdfs://haruna/recommend/data/group_comment/reckon_offline/tfrecord_model/1/', 'Where to write output files.')\n",
    "tf.app.flags.DEFINE_string('last_model_path', '', 'Model path for the previous run.')\n",
    "tf.app.flags.DEFINE_integer(\"train_epochs\", 4, \"train epochs\")\n",
    "tf.app.flags.DEFINE_integer(\"batch_size\", 512, \"batch size\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 1e-4, \"train learning rate\")\n",
    "tf.app.flags.DEFINE_float(\"dropout\", 0.8, \"dropout\")\n",
    "tf.app.flags.DEFINE_float(\"clip_norm\", 10.0, \"clip norm\")\n",
    "tf.app.flags.DEFINE_integer(\"num_cols\", 247, \"num cols\")\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') ## add for jupyter, or error\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "print(FLAGS.model_path)\n",
    "print(FLAGS.train_paths)\n",
    "tf.io.gfile.makedirs(FLAGS.model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_columns(num_cols=247):\n",
    "    columns = []\n",
    "    for i in range(num_cols):\n",
    "        num_column = tf.feature_column.numeric_column(\"slot_%s\"%i)\n",
    "        columns.append(num_column)\n",
    "    return columns\n",
    "build_feature_columns(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_data(paths, batch_size=512, num_epochs=1, shuffle=False, buffer_size=50000, num_cols=247, num_parallels=1, num_workers=1, worker_index=0):\n",
    "    def parse(value):\n",
    "        desc = {\n",
    "                'slot_%s'%i: tf.FixedLenFeature([1], tf.float32, default_value=0.0) for i in range(0, num_cols)\n",
    "            }\n",
    "        desc[\"label\"] = tf.FixedLenFeature([1], tf.int64, default_value=0)\n",
    "        example = tf.parse_single_example(value, desc)\n",
    "        label = example[\"label\"]\n",
    "        label = tf.cast(label,tf.int32)\n",
    "        del example[\"label\"]\n",
    "        return example, label\n",
    "    \n",
    "    print('paths:', paths)\n",
    "    expanded_path = io.expand_paths(paths)\n",
    "    print('expanded_path:', expanded_path)\n",
    "    data_files = tf.data.Dataset.list_files(expanded_path)\n",
    "    print('data_files:', data_files)\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(data_files, num_parallel_reads=num_parallels)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    # dataset = dataset.shard(num_workers, worker_index)\n",
    "\n",
    "    return dataset.map(parse, num_parallel_calls=num_parallels).repeat(num_epochs).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_data = read_data(FLAGS.train_paths, batch_size=5, num_cols=2)\n",
    "with tf.Session() as sess:\n",
    "    batch_item = train_data.take(1)\n",
    "    it = tf.compat.v1.data.make_one_shot_iterator(batch_item)\n",
    "    el = it.get_next()\n",
    "    res = sess.run(el)\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(FLAGS):\n",
    "    print(FLAGS.model_path)\n",
    "    print(FLAGS.last_model_path)\n",
    "    print(FLAGS.learning_rate)\n",
    "    print(FLAGS.clip_norm)\n",
    "    print(FLAGS.num_cols)\n",
    "    print(FLAGS.dropout)\n",
    "    checkpoint_dir = FLAGS.model_path\n",
    "    if FLAGS.last_model_path and not tf.train.latest_checkpoint(checkpoint_dir):\n",
    "        warmup_dir = FLAGS.last_model_path\n",
    "    else:\n",
    "        warmup_dir = None\n",
    "\n",
    "    my_optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, FLAGS.clip_norm)\n",
    "\n",
    "    return tf.estimator.DNNClassifier(\n",
    "        feature_columns=build_feature_columns(FLAGS.num_cols),\n",
    "        hidden_units=[256, 64],\n",
    "        optimizer = my_optimizer,\n",
    "        n_classes = 2,\n",
    "        dropout=FLAGS.dropout,\n",
    "        config=tf.estimator.RunConfig(model_dir=checkpoint_dir),\n",
    "        warm_start_from=warmup_dir)\n",
    "\n",
    "model = build_model(FLAGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn(num_cols=247):\n",
    "    features = {}\n",
    "    for i in range(num_cols):\n",
    "        fname = \"slot_%s\"%(i)\n",
    "        features[fname] = tf.placeholder(tf.float32, shape=[None], name=fname)\n",
    "    return tf.estimator.export.ServingInputReceiver(features, features)\n",
    "\n",
    "receiver_fn = serving_input_receiver_fn(3)\n",
    "print(type(receiver_fn))\n",
    "print(receiver_fn.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return read_data(FLAGS.train_paths,\n",
    "                     batch_size=FLAGS.batch_size,\n",
    "                     num_epochs=FLAGS.train_epochs,\n",
    "                     shuffle=True,\n",
    "                     num_cols=FLAGS.num_cols,\n",
    "                     num_parallels=1)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return read_data(FLAGS.eval_paths,\n",
    "                     batch_size=FLAGS.batch_size,\n",
    "                     num_cols=FLAGS.num_cols,\n",
    "                     num_parallels=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e67e3a49ebaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 serving_input_receiver_fn=serving_input_receiver_fn)\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e67e3a49ebaf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     auc_hook = train.BinaryMetricHook(\n\u001b[1;32m      5\u001b[0m         \u001b[0mnum_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 每积攒了不少于 1000 个样本便触发计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "    model = build_model(FLAGS)\n",
    "    \n",
    "    auc_hook = train.BinaryMetricHook(\n",
    "        num_instances=10000, # 每积攒了不少于 1000 个样本便触发计算\n",
    "        log_auc_steps=50,\n",
    "        score_tensor_name='dnn/head/predictions/logistic:0', # 预估分 Tensor 的名称，形状应为 [?] 或 [?,1]\n",
    "        label_tensor_name='IteratorGetNext:247' # 标签 Tensor 的名称，形状应为 [?] 或 [?,1]\n",
    "    )\n",
    "    hooks = [auc_hook]\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=6000000, hooks=hooks)\n",
    "    \n",
    "    feature_spec = tf.feature_column.make_parse_example_spec(build_feature_columns())\n",
    "    export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "    exporter = tf.estimator.FinalExporter('gandalf', export_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps=100, throttle_secs=10, exporters=[exporter])\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(model, train_spec, eval_spec)\n",
    "    \n",
    "    model.export_saved_model(FLAGS.model_path + '/saved_model', \n",
    "                serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
